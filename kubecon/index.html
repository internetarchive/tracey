<!doctype html><head><script src="../eveal.js/eveal.js"></script></head><body>
<style>code { background-color:#eee; color:#900; }</style>


## Migrating Internet Archive
## to Kubernetes
### KubeCon 2018 - Seattle, WA

<small>
  @tracey_pooh<br/>
  @dvanduzer<br/>

  2018 December 13
</small>

<small>
  _?_ for keyboard shortcuts
</small><br/>
https://github.com/traceypooh/slides

---
<!-- .slide: data-background="ia-truck-cartoon.jpg" -->
<img src="sign.png" style="position:absolute; right:0; top:-250px; min-width:300px; min-height:300px !important; background: 0"/>

<small style="position:fixed; bottom:0; color:white !important">credit: www.flickr.com/photos/cassidy/6898197626</small>

---
# Challenge of Big Changes
<img height="500" data-src="NWL_Press_DontIronWhileStrikeisHot_122116.jpg"/>

---
## What's in it for us?
- language / platform / OS flexibility of Docker 
- model to enforce rebuildable recipes
- more coding; less system building and admin
- fewer "pet" servers
<a href="https://www.youtube.com/watch?time_continue=2&v=vTwJzTsb2QQ">
  <img data-src="i/herding-cats.jpg"/>
</a>

---
# Internet Archive
## a Digital Library
### Curate
### Preserve
### Circulate

---
# Curate all the things!
- 300B+ web pages _WayBack Machine_
- 15M books
- 4M videos & TV News programs
- 4M audio & concerts
- 3M images
- 200K software items & emulation
---
<a href="https://web.archive.org/web/19970404064352/http://www.apple.com:80/">
  <img style="max-height:700px" src="i/wayback-apple.png"/>
</a>
---
<a href="https://archive.org/details/goodytwoshoes00newyiala">
  <img style="max-height:700px" src="i/bookreader.jpg"/>
</a>
---
<a href="https://archive.org/details/msdos_Pac-Man_1983">
  <img style="max-height:700px" src="i/software.png"/>
</a>
---
<a href="https://archive.org/details/Sita_Sings_the_Blues">
  <img style="max-height:700px" src="i/av.jpg"/>
</a>

---
## Curation: First potential Kubernetes Uses
- book scanning apps
- crawl frontier management
- finite duration projects

---
# Preservation
- 50+ petabytes over 22 years
- Fourth generation storage system
- Independence by self-hosting
- Multi-datacenter replication

---
<!-- .slide: data-background="i/container-ship-sink.jpg" -->

---
## Example of Metadata
- Validation & nontampering
  - keep original versions with 2+ checksums and logs
```xml
<file name="commute.mp4" source="derivative">
  <title>commute</title>
  <format>h.264</format>
  <original>commute.avi</original>
  <md5>ff17ed66e7db5693dd208dd6ac488ff8</md5>
  <mtime>1325973601</mtime>
  <size>11919082</size>
  <crc32>ad1df03a</crc32>
  <sha1>e9f9de8379cd25653d487ab30d198fc61a050091</sha1>
  <length>115.61</length>
  <height>480</height>
  <width>640</width>
</file>
```

---
# Circulation
- 300B+ web pages _WayBack Machine_
- 15M books
- 4M videos & TV News programs
- 4M audio & concerts
- 3M images
- 200K software items & emulation

---
## Somewhere in Circulation section
# Library!
- Absolute browser Privacy
  - no personal data or IP addresses extracted

---
## Timeline / Evolution
| Month | Progress
|:--- | ---
| 2014/11 | `docker` for audio fingerprints - controversial
| 2015/10 | `MozFest` OpenNews `docker` talk mind blown
| 2016/8  | switched `mp3/mp4` generation to `docker`
| 2017/6  | <a href="https://archive.org/~tracey/docker-talker">IA Engr. Presentation</a>
| 2018/6  | <a href="https://archive.org/~tracey/kubernetes-special-topic">IA Engr. Special Topic talk</a>
| 2018/7  | <a href="https://archive.org/~tracey/auto-devops">_GitLab 'Auto DevOps'_ Changes Everything - Dev & Ops Harmony - Confessions of a middle child</a>

---
# LogJam BreakThroughs
- TeamUp! (end of 2017)
  - David (ops-heavy history)
  - Tracey (dev-heavy history)
- GitLab advertises `with Kubernetes` July/2018
  - _already using_ 'on premise' `GitLab` for repos
  - w/ ssh-key user accounts .org-wide

---
## Timeline / Evolution
| Month | Moves into GitLab Auto DevOps Kubernetes
|:--- | ---
| 2018/8  | archive.org main repo CI/`test` migrated
| 2018/9  | archive.org full pipelines, <a href="https://ia-petabox.archive.org/">website 'review apps'</a>
| 2018/10 | bookscan webapps
| 2018/10 | moved to GitLab's docker registry
| 2018/12 | <a href="https://dweb.archive.org/">dweb.archive.org</a> (archive.org decentralized)

---
# .. But!
- still more comfortable w/ block-device storage than torrented pieces for entire data Archives
  - eg: S3 => K8 or o/w -- seems anxiety++

---
# Avoid Bad Blood
<a href="https://www.youtube.com/watch?v=QcIy9NiNbmo">
  <img data-src="bad-blood.jpg"/>
</a>

---
## Work Towards Common Goals
Devs & Ops
<a href="https://en.wikipedia.org/wiki/The_Uncanny_X-Men_and_The_New_Teen_Titans">
  <img data-src="harmony.jpg"/>
</a>

---
# www-NAME (bespoke) -v- review apps (GitLab + k8)
webapps quick development at archive.org

---
## Auto DevOps Pipelines
<img src="../auto-devops/pipeline.png"/>

---
# www-tracey.archive.org
- ssh 'bastion' with homedirs
- NFS /home/ automounts throughout cluster
- edit:
  - emacs/vi on (linux) bastion
  - laptop editors with sftp / rsync-over-ssh on `[save]`
- nginx virtual hosts
  - https://archive.org => `/petabox/www/..` (production)
  - https://www-NAME.archive.org => `/home/NAME/petabox/www/..` (dev)

---
## www-NAME.archive.org issues
- single 'dest' (multiple branches tricky)
- ssh keys and acccess
- NFS /home/ dirs

---
## K8 + Auto DevOps 'review apps'
- contractors can work/test full site
  - w/o ssh keys/access
  - 12h timezone shift OK
    - no staff/approval need - `game changer!`
- git branches => 'review apps' consistent/update over time
- `kre8/branch-sync-edit.sh`
  - 'copy file change to pod on save' fast script
  - webapp instant f/b w/o full push and CI/CD

---
# Crawling Case Study

---
## Anatomy of Archival Crawling
1. Start with a list of websites
2. Fetch all those URLs
3. Extract Hyperlinks from all the fetched content
  - Now you have a list of websites again
  - Which you can Fetch and Extract and...
4. Serialize captures into WARC (Web Archive) format
5. Persist to permanent item storage

---
## Heritrix
- open source Java crawler developed at IA
- very good at pipelining these stages
- but, single machine operation

## CrawlHQ
- distributed frontier management
- multiple Heritrix instances share single URL deduplication queue

---
## Rewriting CrawlHQ as Demo of K8S auto-scaling
- Kafka partitions for work queue
- FoundationDB for hashes of seen URLs
- 38,000 lines of code is now 73 lines of Python
- throughput scales automatically with GitLab `REPLICAS` variable

---
<!-- .slide: data-background="black" -->
<iframe src="https://archive.org/embed/kubecon-monolith" width="960" height="540" frameborder="0" webkitallowfullscreen="true" mozallowfullscreen="true" allowfullscreen></iframe>
<!-- video src="Monolith.mp4" autoplay controls mozallowfullscreen webkitallowfullscreen allowfullscreen -->

---
# MonoRepo speed++
- 4.8G tree => 6GB .. 9GB docker images
- `test` phase _first_ = faster (when possible)
- takeover git mgmt
  - naive `git clone` every CI/CD phase = nonstarter
- build/test code in same tree
  - `RUN ..` move git tree up to head of master first
  - `RUN ..` reinvoke build script (now at master);
    - move git tree pointer back to `$COMMIT`

---
# Monorepo .git
- `$FETCH` either:
  - `master:master`
  - `master:master my-awesome-branch:ca6745`
- `$CHECKOUT` either:
  - `master` or `my-awesome-branch` (head) or `ca6745`
- `git shallow clone`
  - (docker image basis; recut weekly or so; baseline image used in each phase)

---
# Monorepo .git
- `git checkout --detach`
  - avoid tangle with git tree state
- `git fetch -depth 1 -f -origin $FETCH`
  - git 'advertised' commits
  - ```omnibus_gitconfig['system'] = {"uploadpack" => ["allowReachableSHA1InWant = true"]}```
- `git checkout -f $CHECKOUT`
  - reset HEAD pointer to state in _origin's_ branch/commit
  - (makes concept of branch/commit now same as origin's)
- `build` pull from prior branch's build saved in registry

---
## because we have _this_ guy and you don't
<img data-src="git-pro.jpg"><br/>
^ git pro


---
# 'on prem' K8 cluster from scratch
- https://gitlab.com/internetarchive/kre8
  <img style="width:10%; vertical-align:middle" data-src="i/pirate-coin-rotated-small.png"/>
  - shows/uses GitLab 'Auto DevOps' CI/CD end-to-end
  - need 1+ VM w/ ssh access and sudo
    - (ubuntu based so far)
  - uses `kubeadm`
  - coworker can try out - low committment
  - `kallr`

---
# Top Tips
- `POSTGRES_ENABLED=false` CI/CD var
  - avoids extra (unused!) PV per branch/deploy
- can use simple `localstorage` for 1 (tainted) or 2-node k8 clusters
- periodically: remove old replicasets, trim registry
- GitLab API for last master `test` phase status
  - 'OK to push live?'

---
## LoadBalancer vs Ingress for Alt Ports
- `kubectl expose -ndweb deployment/production --type=LoadBalancer --name=porter`
- `kubectl patch  -ndweb svc/porter -p='{"spec":{"externalIPs":["'${K8_INGRESS_IP?}"]}}'`
- allows for non :80 :443 :5000 ports
  - websockets!
    - wss://dweb.me:4246
    - ws:// possible too

---
# Wish List
- better/automated cleaning:
  - older docker images/containers on K8 nodes
  - older registry images in GitLab

---
# Near Future
- archive.org production website to K8
  - turn on elastic demand-based scaling
  - (static lists of VMs now)

---
<!-- .slide: data-background="https://media.giphy.com/media/Gdjgn0hy8zBRK/giphy.gif" -->
# The End

